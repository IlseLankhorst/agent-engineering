{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first take-home project will be a chance to get some hands-on practice with the concepts of Week 1 for an agent task of your choice.\n",
    "\n",
    "Goal:\n",
    "\n",
    "- Choose a task involving multi-turn interaction/tool use\n",
    "- Implement an agent scaffold either using an API directly, or one of the frameworks we covered\n",
    "- Create a small set of \"test prompts\"\n",
    "- Create a \"reward function\" to evaluate your agent\n",
    "- Test your agent setup with multiple models/prompts\n",
    "- Examine multiple agent outputs, identify a consistent \"problem\", adjust the setup (prompts/tools) OR adjust your evals to measure/address the problem\n",
    "\n",
    "Ideas for agent tasks:\n",
    "- Search agent for your favorite blog/website\n",
    "- Agent which\n",
    "- Agent for playing a simple board/card game\n",
    "- Code agent specialized to only use a specific library, e.g. iterating on a matplotlib plot until it \"looks right\"\n",
    "- Terminal-based chat agent with user handoff/confirmation\n",
    "\n",
    "Ideas for reward functions:\n",
    "- Format checks using regex\n",
    "- Deterministic checks (parsing math answers, running code with test cases, solving a puzzle/game)\n",
    "- Embedding or text overlap similarity to a \"ground truth\"\n",
    "- LLM judges which can see the \"ground truth\"\n",
    "- LLM judges which evaluate a set of fuzzy criteria + give scores for each\n",
    "\n",
    "Tips:\n",
    "- Start simple, get a basic version working, then ramp up complexity\n",
    "- If your agent \"just works\" with a fairly powerful model, try it with a weaker model and see what breaks\n",
    "\n",
    "\n",
    "Bonus goals:\n",
    "- Try making a \"parallel-friendly\" version using asyncio + error handling\n",
    "- Try implementing Best-of-N selection -- can your eval function match your judgment for which outputs are \"best\"?\n",
    "- Try testing either a \"multi-agent\" (parallelized) version of your agent, OR a Client/Server version (e.g. MCP, A2A)\n",
    "\n",
    "\n",
    "Deliverable:\n",
    "- A repo, notebook, *or* short writeup detailing your setup + experimentation\n",
    "- What approaches did you try?\n",
    "- What roadblocks did you run into?\n",
    "- Which evaluation methods worked best for your task?\n",
    "- What's the smallest model that worked decently well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# simplest possible LLM call\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "oai = OpenAI()\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "class SimpleLineageAgent:\n",
    "    \"\"\"Basic lineage agent using only LLM\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4.1-mini\"):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "    \n",
    "    def analyze_lineage(self, code: str, target_variable: str) -> str:\n",
    "        \"\"\"Analyze lineage using only LLM\"\"\"\n",
    "        \n",
    "        system_prompt = \"\"\"You are a data engineer which needs to analyze the lineage of a target variable to refactor the code. \n",
    "        \n",
    "        Analyze the code and explain how the target variable was created:\n",
    "        1. What source tables/files were used\n",
    "        2. What operations were performed \n",
    "        3. The step-by-step data flow\n",
    "        \n",
    "        Be clear and concise.\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Variable to analyze: {target_variable}\n",
    "        \n",
    "        Code:\n",
    "        ```\n",
    "        {code}\n",
    "        ```\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Lineage Analysis ===\n",
      "Code:\n",
      "\n",
      "# Load data\n",
      "transactions = spark.table(\"raw.transactions\")\n",
      "customers = spark.table(\"raw.customers\")\n",
      "\n",
      "# Filter recent transactions\n",
      "recent_tx = transactions.filter(col(\"date\") >= \"2023-01-01\")\n",
      "\n",
      "# Group by customer\n",
      "customer_totals = recent_tx.groupBy(\"customer_id\").sum(\"amount\")\n",
      "\n",
      "# Join with customer names\n",
      "final_result = customer_totals.join(customers, \"customer_id\")\n",
      "\n",
      "\n",
      "==================================================\n",
      "Analyzing 'final_result':\n",
      "1. Source tables/files used:\n",
      "   - \"raw.transactions\" table\n",
      "   - \"raw.customers\" table\n",
      "\n",
      "2. Operations performed:\n",
      "   - Load the two tables into Spark DataFrames.\n",
      "   - Filter the transactions to keep only those from January 1, 2023, onwards.\n",
      "   - Group the filtered transactions by customer_id and sum the amount for each customer.\n",
      "   - Join the aggregated transaction totals with the customers table on customer_id.\n",
      "\n",
      "3. Step-by-step data flow:\n",
      "   - Load \"raw.transactions\" into `transactions`.\n",
      "   - Load \"raw.customers\" into `customers`.\n",
      "   - Filter `transactions` to create `recent_tx` with transactions dated >= \"2023-01-01\".\n",
      "   - Aggregate `recent_tx` by customer_id, summing the amount column, resulting in `customer_totals`.\n",
      "   - Join `customer_totals` with `customers` on customer_id to produce `final_result`, which contains customer details along with their total transaction amounts since 2023-01-01.\n",
      "\n",
      "------------------------------\n",
      "Analyzing 'customer_totals':\n",
      "1. Source tables/files used:\n",
      "   - `raw.transactions` table\n",
      "   - `raw.customers` table\n",
      "\n",
      "2. Operations performed:\n",
      "   - Load the `transactions` and `customers` tables into Spark DataFrames.\n",
      "   - Filter the `transactions` DataFrame to keep only records with a `date` on or after \"2023-01-01\".\n",
      "   - Group the filtered transactions by `customer_id` and calculate the sum of the `amount` for each customer.\n",
      "   - Join the aggregated totals with the `customers` DataFrame on `customer_id`.\n",
      "\n",
      "3. Step-by-step data flow:\n",
      "   - Read `raw.transactions` into `transactions`.\n",
      "   - Read `raw.customers` into `customers`.\n",
      "   - Filter `transactions` to create `recent_tx` containing only transactions from 2023 onwards.\n",
      "   - Aggregate `recent_tx` by `customer_id` to compute total transaction amounts, resulting in `customer_totals`.\n",
      "   - Join `customer_totals` with `customers` on `customer_id` to enrich totals with customer details, producing `final_result`.\n",
      "\n",
      "The target variable `customer_totals` specifically represents the sum of transaction amounts per customer for transactions dated from 2023-01-01 onwards.\n"
     ]
    }
   ],
   "source": [
    "# Simple test function\n",
    "\n",
    "sample_code = '''\n",
    "# Load data\n",
    "transactions = spark.table(\"raw.transactions\")\n",
    "customers = spark.table(\"raw.customers\")\n",
    "\n",
    "# Filter recent transactions\n",
    "recent_tx = transactions.filter(col(\"date\") >= \"2023-01-01\")\n",
    "\n",
    "# Group by customer\n",
    "customer_totals = recent_tx.groupBy(\"customer_id\").sum(\"amount\")\n",
    "\n",
    "# Join with customer names\n",
    "final_result = customer_totals.join(customers, \"customer_id\")\n",
    "'''\n",
    "    \n",
    "agent = SimpleLineageAgent()\n",
    "\n",
    "print(\"=== Simple Lineage Analysis ===\")\n",
    "print(f\"Code:\\n{sample_code}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test analyzing final_result\n",
    "print(\"Analyzing 'final_result':\")\n",
    "result = agent.analyze_lineage(sample_code, \"final_result\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "\n",
    "# Test analyzing intermediate variable\n",
    "print(\"Analyzing 'customer_totals':\")\n",
    "result2 = agent.analyze_lineage(sample_code, \"customer_totals\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Lineage Analysis ===\n",
      "Code:\n",
      "\n",
      "# Load data\n",
      "transactions = spark.table(\"raw.transactions\")\n",
      "customers = spark.table(\"raw.customers\")\n",
      "\n",
      "# Filter recent transactions\n",
      "recent_tx = transactions.filter(col(\"date\") >= \"2023-01-01\")\n",
      "\n",
      "# Group by customer\n",
      "customer_totals = recent_tx.groupBy(\"customer_id\").sum(\"amount\")\n",
      "\n",
      "# Join with customer names\n",
      "final_result = customer_totals.join(customers, \"customer_id\")\n",
      "\n",
      "\n",
      "==================================================\n",
      "Analyzing 'final_result':\n",
      "The target variable `final_result` was created through the following data flow:\n",
      "\n",
      "1. **Source Tables:**\n",
      "   - `raw.transactions`: Contains transaction data, including `customer_id`, `amount`, and `date`.\n",
      "   - `raw.customers`: Contains customer details, including `customer_id` and customer name information.\n",
      "\n",
      "2. **Operations Performed:**\n",
      "   - Filtered `transactions` to include only recent transactions from January 1, 2023, onwards (`recent_tx`).\n",
      "   - Aggregated `recent_tx` by `customer_id` to compute the total transaction amount per customer (`customer_totals`).\n",
      "   - Joined `customer_totals` with `customers` on `customer_id` to associate customer details with their total transaction amounts.\n",
      "\n",
      "3. **Data Flow Step-by-Step:**\n",
      "   - Load `transactions` and `customers` tables.\n",
      "   - Filter `transactions` for dates >= 2023-01-01.\n",
      "   - Group the filtered transactions by `customer_id` and sum the `amount` to get total amounts per customer.\n",
      "   - Join the aggregated totals with the `customers` table to include customer information.\n",
      "   - The resulting DataFrame, `final_result`, contains customer details along with their total transaction amount since the specified date.\n",
      "\n",
      "------------------------------\n",
      "Analyzing 'customer_totals':\n",
      "The target variable `customer_totals` was created through the following data flow:\n",
      "\n",
      "1. **Source Tables Used:**\n",
      "   - `raw.transactions`: Contains transaction records, including `customer_id`, `amount`, and `date`.\n",
      "   - `raw.customers`: Contains customer details, including `customer_id` and customer name.\n",
      "\n",
      "2. **Operations Performed:**\n",
      "   - Filtering: The `transactions` table is filtered to include only recent transactions with `date` on or after \"2023-01-01\".\n",
      "   - Aggregation: The filtered transactions (`recent_tx`) are grouped by `customer_id`, and the sum of `amount` is calculated for each customer, resulting in `customer_totals`.\n",
      "\n",
      "3. **Data Flow Step-by-Step:**\n",
      "   - Load `transactions` and `customers` tables.\n",
      "   - Filter `transactions` to keep only recent transactions (`recent_tx`).\n",
      "   - Group `recent_tx` by `customer_id` and compute the total `amount` per customer, creating `customer_totals`.\n",
      "   - The `customer_totals` table is then joined with `customers` to associate customer names, resulting in `final_result`.\n",
      "\n",
      "**Note:** The creation of `customer_totals` involves filtering and aggregation of transaction data, but it does not include the join with customer details.\n"
     ]
    }
   ],
   "source": [
    "# Simple test function\n",
    "\n",
    "sample_code = '''\n",
    "# Load data\n",
    "transactions = spark.table(\"raw.transactions\")\n",
    "customers = spark.table(\"raw.customers\")\n",
    "\n",
    "# Filter recent transactions\n",
    "recent_tx = transactions.filter(col(\"date\") >= \"2023-01-01\")\n",
    "\n",
    "# Group by customer\n",
    "customer_totals = recent_tx.groupBy(\"customer_id\").sum(\"amount\")\n",
    "\n",
    "# Join with customer names\n",
    "final_result = customer_totals.join(customers, \"customer_id\")\n",
    "'''\n",
    "    \n",
    "agent = SimpleLineageAgent(model=\"gpt-4.1-nano\")\n",
    "\n",
    "print(\"=== Simple Lineage Analysis ===\")\n",
    "print(f\"Code:\\n{sample_code}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Test analyzing final_result\n",
    "print(\"Analyzing 'final_result':\")\n",
    "result = agent.analyze_lineage(sample_code, \"final_result\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "\n",
    "# Test analyzing intermediate variable\n",
    "print(\"Analyzing 'customer_totals':\")\n",
    "result2 = agent.analyze_lineage(sample_code, \"customer_totals\")\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGENT WITH SYSTEM PROMPT + TOOLS ===\n",
      "**Sources:**  \n",
      "- The data for `sales` comes from the file `sales_data.csv`.  \n",
      "- The data for `customers` comes from the file `customers.csv`.\n",
      "\n",
      "**Operations:**  \n",
      "- The `sales` data is filtered to include only recent sales from January 1, 2023, onward.  \n",
      "- The filtered `sales` data (`recent_sales`) is grouped by `customer_id`, summing the `amount` for each customer to get `customer_totals`.  \n",
      "- Finally, `customer_totals` is merged (joined) with the `customers` data on the `customer_id` to produce the `final_result`.\n",
      "\n",
      "**Flow:**  \n",
      "1. Data loads from two CSV files: sales and customer information.  \n",
      "2. The sales data is filtered to keep only recent transactions from 2023 onwards.  \n",
      "3. This filtered data is grouped by customer IDs, summing up the purchase amounts per customer.  \n",
      "4. The summarized sales data (`customer_totals`) is then merged with customer details to combine total spending with customer information, resulting in `final_result`.\n",
      "\n",
      "This process captures where the data originates and how it's transformed step-by-step to produce the final result.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "from openai import OpenAI\n",
    "\n",
    "@function_tool\n",
    "async def extract_sources_tool(code: str) -> list[str]:\n",
    "    \"\"\"Extract data sources from code\n",
    "    \n",
    "    Args:\n",
    "        code (str): The code to analyze\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: List of data sources found (files, tables, etc.)\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'pd\\.read_csv\\s*\\(\\s*[\"\\']([^\"\\']+)[\"\\']',\n",
    "        r'spark\\.table\\s*\\(\\s*[\"\\']([^\"\\']+)[\"\\']',\n",
    "        r'pd\\.read_parquet\\s*\\(\\s*[\"\\']([^\"\\']+)[\"\\']'\n",
    "    ]\n",
    "    \n",
    "    sources = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, code)\n",
    "        sources.extend(matches)\n",
    "    \n",
    "    return list(set(sources))\n",
    "\n",
    "@function_tool\n",
    "async def extract_operations_tool(code: str) -> list[str]:\n",
    "    \"\"\"Extract operations from code\n",
    "    \n",
    "    Args:\n",
    "        code (str): The code to analyze\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: List of operations found (filter, groupby, join, etc.)\n",
    "    \"\"\"\n",
    "    operations = []\n",
    "    \n",
    "    if '.filter(' in code or '.query(' in code:\n",
    "        operations.append('filter')\n",
    "    if '.groupby(' in code or '.groupBy(' in code:\n",
    "        operations.append('groupby') \n",
    "    if '.join(' in code or '.merge(' in code:\n",
    "        operations.append('join')\n",
    "    if '.sum(' in code:\n",
    "        operations.append('sum')\n",
    "    if '.mean(' in code:\n",
    "        operations.append('mean')\n",
    "        \n",
    "    return operations\n",
    "\n",
    "lineage_agent = Agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    name=\"advanced_lineage_agent\",\n",
    "    \n",
    "    # SYSTEM PROMPT: Instructions for HOW to behave\n",
    "    instructions=\"\"\"You are an expert data lineage analyst. Your job is to help users understand how their data flows through code.\n",
    "\n",
    "    **Your approach:**\n",
    "    1. Always use your tools to extract technical details first\n",
    "    2. Think step-by-step about the data flow\n",
    "    3. Explain things clearly for both technical and non-technical users\n",
    "    4. Be thorough but concise\n",
    "    \n",
    "    **When analyzing code:**\n",
    "    - First, use extract_sources_tool to find all data sources\n",
    "    - Then, use extract_operations_tool to find all operations\n",
    "    - Finally, synthesize this information into a clear explanation\n",
    "    \n",
    "    **Always think step-by-step before calling a tool.**\n",
    "    \n",
    "    Format your final answer with:\n",
    "    - Sources: What data comes from\n",
    "    - Operations: What happens to the data  \n",
    "    - Flow: Step-by-step explanation\"\"\",\n",
    "    \n",
    "    # TOOLS: What the agent CAN DO\n",
    "    tools=[extract_sources_tool, extract_operations_tool],\n",
    ")\n",
    "\n",
    "sample_code = '''\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "sales = pd.read_csv(\"sales_data.csv\")\n",
    "customers = pd.read_csv(\"customers.csv\")\n",
    "\n",
    "# Process data\n",
    "recent_sales = sales.query(\"date >= '2023-01-01'\")\n",
    "customer_totals = recent_sales.groupby('customer_id')['amount'].sum()\n",
    "final_result = customer_totals.merge(customers, on='customer_id')\n",
    "'''\n",
    "    \n",
    "prompt = f\"\"\"\n",
    "Analyze the lineage of the variable 'final_result' in this code:\n",
    "\n",
    "{sample_code}\n",
    "\n",
    "I need to understand where the data comes from and how it's transformed.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== AGENT WITH SYSTEM PROMPT + TOOLS ===\")\n",
    "result = await Runner.run(lineage_agent, prompt)\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunResult' object has no attribute 'usage'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43musage\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunResult' object has no attribute 'usage'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ TESTING CODE ANALYSIS TOOLS\n",
      "==================================================\n",
      "ðŸ“ Sources found:\n",
      "['sales_data.csv', 'customers.csv']\n",
      "\n",
      "ðŸ“ Variable assignments:\n",
      "  sales: lines [5]\n",
      "  customers: lines [6]\n",
      "  recent_sales: lines [9]\n",
      "  customer_totals: lines [10]\n",
      "  final_result: lines [11]\n",
      "\n",
      "âš™ï¸ Operations found:\n",
      "  Line 9: filter - recent_sales = sales.query(\"date >= '2023-01-01'\")\n",
      "  Line 10: groupby - customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
      "  Line 10: reset_index - customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
      "  Line 10: agg_sum - customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
      "  Line 10: groupBy - customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
      "  Line 10: sql_SUM - customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
      "  Line 11: merge - final_result = customer_totals.merge(customers, on='customer_id')\n",
      "\n",
      "ðŸŽ¯ Trace 'final_result':\n",
      "  Sources: ['sales_data.csv', 'customers.csv']\n",
      "  Operations: ['filter', 'merge', 'groupby', 'agg_sum', 'reset_index', 'groupBy', 'sql_SUM']\n",
      "  Assignment lines: [11]\n"
     ]
    }
   ],
   "source": [
    "from tools import CodeAnalysisTools\n",
    "\n",
    "sample_code = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "sales = pd.read_csv(\"sales_data.csv\")\n",
    "customers = pd.read_csv(\"customers.csv\")\n",
    "\n",
    "# Process data\n",
    "recent_sales = sales.query(\"date >= '2023-01-01'\")\n",
    "customer_totals = recent_sales.groupby('customer_id')['amount'].sum().reset_index()\n",
    "final_result = customer_totals.merge(customers, on='customer_id')\n",
    "\"\"\"\n",
    "\n",
    "tools = CodeAnalysisTools()\n",
    "\n",
    "print(\"ðŸ”§ TESTING CODE ANALYSIS TOOLS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ðŸ“ Sources found:\")\n",
    "sources = tools.extract_table_sources(sample_code)\n",
    "print(sources)\n",
    "\n",
    "print(\"\\nðŸ“ Variable assignments:\")\n",
    "assignments = tools.extract_variable_assignments(sample_code)\n",
    "for var, lines in assignments.items():\n",
    "    print(f\"  {var}: lines {lines}\")\n",
    "\n",
    "print(\"\\nâš™ï¸ Operations found:\")\n",
    "operations = tools.extract_operations(sample_code)\n",
    "for op in operations:\n",
    "    print(f\"  Line {op['line']}: {op['operation']} - {op['code']}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Trace 'final_result':\")\n",
    "trace = tools.trace_variable_dependencies(sample_code, \"final_result\")\n",
    "print(f\"  Sources: {trace['sources']}\")\n",
    "print(f\"  Operations: {trace['operations']}\")\n",
    "print(f\"  Assignment lines: {trace['assignment_lines']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def compare_tool_vs_llm(self, code: str, target_variable: str) -> dict[str, any]:\n",
    "    #     \"\"\"Compare tool analysis vs LLM analysis\"\"\"\n",
    "\n",
    "    #     # Tool analysis\n",
    "    #     tool_result = self.trace_variable_dependencies(code, target_variable)\n",
    "\n",
    "    #     # Pure LLM analysis (without tools)\n",
    "    #     system_prompt = \"\"\"You are a code lineage analysis expert.\n",
    "\n",
    "    #     Analyze the code to trace how the target variable was created:\n",
    "    #     1. What source tables/files were used\n",
    "    #     2. What operations were performed\n",
    "    #     3. The step-by-step flow\"\"\"\n",
    "\n",
    "    #     user_prompt = f\"Target variable: {target_variable}\\n\\nCode:\\n```\\n{code}\\n```\"\n",
    "\n",
    "    #     llm_response = self.client.chat.completions.create(\n",
    "    #         model=self.model,\n",
    "    #         messages=[\n",
    "    #             {\"role\": \"system\", \"content\": system_prompt},\n",
    "    #             {\"role\": \"user\", \"content\": user_prompt},\n",
    "    #         ],\n",
    "    #         temperature=0,\n",
    "    #     )\n",
    "\n",
    "    #     # Enhanced analysis (tools + LLM)\n",
    "    #     enhanced_response = self.analyze_lineage_with_tools(code, target_variable)\n",
    "\n",
    "    #     return {\n",
    "    #         \"tool_analysis\": tool_result,\n",
    "    #         \"llm_only\": llm_response.choices[0].message.content,\n",
    "    #         \"enhanced_analysis\": enhanced_response,\n",
    "    #     }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
